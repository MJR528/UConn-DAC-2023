{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DAC Contest\n",
    "This reference design will help you walk through a design flow of DAC SDC 2023. This is a simplified design to help users get started on the FPGA platform and to understand the overall flow. It does not contain any object detection hardware.\n",
    "\n",
    "If you have any questions, please post on the Slack page (link on SDC website sidebar).\n",
    "\n",
    "### Hardware\n",
    "\n",
    "### Software\n",
    "Note:\n",
    "  * You will not submit your `dac_sdc.py` file, so any changes you make to this file will not be considered during evluation.  \n",
    "  * You can use both PS and PL side to do inference.\n",
    "\n",
    "### Object Detection\n",
    "\n",
    "Object detection will be done on images in batches:\n",
    "  * You will provide a Python callback function that will perform object detection on batch of images.  This callback function wile be called many times.\n",
    "  * The callback function should return the locations of all images in the batch.\n",
    "  * Runtime will be recorded during your callback function.\n",
    "  * Images will be loaded from SD card before each batch is run, and this does not count toward your energy usage or runtime.\n",
    "  \n",
    "### Notebook\n",
    "Your notebook should contain 4 code cells:\n",
    "\n",
    "1. Importing all libraries and creating your Team object.\n",
    "1. Downloading the overlay, compile the code, and performany any one-time configuration.\n",
    "1. Python callback function and any other Python helper functions.\n",
    "1. Running object detection\n",
    "1. Cleanup\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports and Create Team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../common\"))\n",
    "\n",
    "import math\n",
    "import time\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot\n",
    "import cv2\n",
    "from datetime import datetime\n",
    "import torchvision\n",
    "\n",
    "\n",
    "import dac_sdc\n",
    "from IPython.display import display\n",
    "\n",
    "team_name = 'BFGPU'\n",
    "dac_sdc.BATCH_SIZE = 2\n",
    "team = dac_sdc.Team(team_name)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your team directory where you can access your notebook, and any other files you submit, is available as `team.team_dir`.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preparing the library and model\n",
    "Prepare the dependencies for the contest, including installing python packages, compiling your binaries, and linking to the notebook.\n",
    "\n",
    "Your team is responsible to make sure the correct packages are installed. For the contest environment, use the configuration below provided by Nvidia:\n",
    "\n",
    "- Ubuntu 18.04\n",
    "- CUDA XXX\n",
    "- CUDNN XXX\n",
    "- GCC XXX\n",
    "- ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShuffleV2Block(nn.Module):\n",
    "    def __init__(self, inp, oup, mid_channels, *, ksize, stride):\n",
    "        super(ShuffleV2Block, self).__init__()\n",
    "        self.stride = stride\n",
    "        assert stride in [1, 2]\n",
    "\n",
    "        self.mid_channels = mid_channels\n",
    "        self.ksize = ksize\n",
    "        pad = ksize // 2\n",
    "        self.pad = pad\n",
    "        self.inp = inp\n",
    "\n",
    "        outputs = oup - inp\n",
    "\n",
    "        branch_main = [\n",
    "            # pw\n",
    "            nn.Conv2d(inp, mid_channels, 1, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(mid_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # dw\n",
    "            nn.Conv2d(\n",
    "                mid_channels,\n",
    "                mid_channels,\n",
    "                ksize,\n",
    "                stride,\n",
    "                pad,\n",
    "                groups=mid_channels,\n",
    "                bias=False,\n",
    "            ),\n",
    "            nn.BatchNorm2d(mid_channels),\n",
    "            # pw-linear\n",
    "            nn.Conv2d(mid_channels, outputs, 1, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(outputs),\n",
    "            nn.ReLU(inplace=True),\n",
    "        ]\n",
    "        self.branch_main = nn.Sequential(*branch_main)\n",
    "\n",
    "        if stride == 2:\n",
    "            branch_proj = [\n",
    "                # dw\n",
    "                nn.Conv2d(inp, inp, ksize, stride, pad, groups=inp, bias=False),\n",
    "                nn.BatchNorm2d(inp),\n",
    "                # pw-linear\n",
    "                nn.Conv2d(inp, inp, 1, 1, 0, bias=False),\n",
    "                nn.BatchNorm2d(inp),\n",
    "                nn.ReLU(inplace=True),\n",
    "            ]\n",
    "            self.branch_proj = nn.Sequential(*branch_proj)\n",
    "        else:\n",
    "            self.branch_proj = None\n",
    "\n",
    "    def forward(self, old_x):\n",
    "        if self.stride == 1:\n",
    "            x_proj, x = self.channel_shuffle(old_x)\n",
    "            return torch.cat((x_proj, self.branch_main(x)), 1)\n",
    "        elif self.stride == 2:\n",
    "            x_proj = old_x\n",
    "            x = old_x\n",
    "            return torch.cat((self.branch_proj(x_proj), self.branch_main(x)), 1)\n",
    "\n",
    "    def channel_shuffle(self, x):\n",
    "        batchsize, num_channels, height, width = x.data.size()\n",
    "        assert num_channels % 4 == 0\n",
    "        x = x.reshape(batchsize * num_channels // 2, 2, height * width)\n",
    "        x = x.permute(1, 0, 2)\n",
    "        x = x.reshape(2, -1, num_channels // 2, height, width)\n",
    "        return x[0], x[1]\n",
    "\n",
    "\n",
    "class ShuffleNetV2(nn.Module):\n",
    "    def __init__(self, stage_repeats, stage_out_channels, load_param):\n",
    "        super(ShuffleNetV2, self).__init__()\n",
    "\n",
    "        self.stage_repeats = stage_repeats\n",
    "        self.stage_out_channels = stage_out_channels\n",
    "\n",
    "        # building first layer\n",
    "        input_channel = self.stage_out_channels[1]\n",
    "        self.first_conv = nn.Sequential(\n",
    "            nn.Conv2d(3, input_channel, 3, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(input_channel),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        stage_names = [\"stage2\", \"stage3\", \"stage4\"]\n",
    "        for idxstage in range(len(self.stage_repeats)):\n",
    "            numrepeat = self.stage_repeats[idxstage]\n",
    "            output_channel = self.stage_out_channels[idxstage + 2]\n",
    "            stageSeq = []\n",
    "            for i in range(numrepeat):\n",
    "                if i == 0:\n",
    "                    stageSeq.append(\n",
    "                        ShuffleV2Block(\n",
    "                            input_channel,\n",
    "                            output_channel,\n",
    "                            mid_channels=output_channel // 2,\n",
    "                            ksize=3,\n",
    "                            stride=2,\n",
    "                        )\n",
    "                    )\n",
    "                else:\n",
    "                    stageSeq.append(\n",
    "                        ShuffleV2Block(\n",
    "                            input_channel // 2,\n",
    "                            output_channel,\n",
    "                            mid_channels=output_channel // 2,\n",
    "                            ksize=3,\n",
    "                            stride=1,\n",
    "                        )\n",
    "                    )\n",
    "                input_channel = output_channel\n",
    "            setattr(self, stage_names[idxstage], nn.Sequential(*stageSeq))\n",
    "\n",
    "        if load_param == False:\n",
    "            self._initialize_weights()\n",
    "        else:\n",
    "            print(\"load param...\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.first_conv(x)\n",
    "        x = self.maxpool(x)\n",
    "        P1 = self.stage2(x)\n",
    "        P2 = self.stage3(P1)\n",
    "        P3 = self.stage4(P2)\n",
    "\n",
    "        return P1, P2, P3\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        print(\"Initialize params from:%s\" % \"./module/shufflenetv2.pth\")\n",
    "        self.load_state_dict(torch.load(\"./module/shufflenetv2.pth\"), strict=True)\n",
    "class Conv1x1(nn.Module):\n",
    "    def __init__(self, input_channels, output_channels):\n",
    "        super(Conv1x1, self).__init__()\n",
    "        self.conv1x1 = nn.Sequential(nn.Conv2d(input_channels, output_channels, 1, stride=1, padding=0, bias=False),\n",
    "                                     nn.BatchNorm2d(output_channels),\n",
    "                                     nn.ReLU(inplace=True)\n",
    "                                     )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv1x1(x)\n",
    "\n",
    "\n",
    "class Head(nn.Module):\n",
    "    def __init__(self, input_channels, output_channels):\n",
    "        super(Head, self).__init__()\n",
    "        self.conv5x5 = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, input_channels, 5, 1, 2, groups=input_channels, bias=False),\n",
    "            nn.BatchNorm2d(input_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(input_channels, output_channels, 1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(output_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv5x5(x)\n",
    "\n",
    "\n",
    "class SPP(nn.Module):\n",
    "    def __init__(self, input_channels, output_channels):\n",
    "        super(SPP, self).__init__()\n",
    "        self.Conv1x1 = Conv1x1(input_channels, output_channels)\n",
    "\n",
    "        self.S1 = nn.Sequential(\n",
    "            nn.Conv2d(output_channels, output_channels, 5, 1, 2, groups=output_channels, bias=False),\n",
    "            nn.BatchNorm2d(output_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.S2 = nn.Sequential(\n",
    "            nn.Conv2d(output_channels, output_channels, 5, 1, 2, groups=output_channels, bias=False),\n",
    "            nn.BatchNorm2d(output_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(output_channels, output_channels, 5, 1, 2, groups=output_channels, bias=False),\n",
    "            nn.BatchNorm2d(output_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.S3 = nn.Sequential(\n",
    "            nn.Conv2d(output_channels, output_channels, 5, 1, 2, groups=output_channels, bias=False),\n",
    "            nn.BatchNorm2d(output_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(output_channels, output_channels, 5, 1, 2, groups=output_channels, bias=False),\n",
    "            nn.BatchNorm2d(output_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(output_channels, output_channels, 5, 1, 2, groups=output_channels, bias=False),\n",
    "            nn.BatchNorm2d(output_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.output = nn.Sequential(nn.Conv2d(output_channels * 3, output_channels, 1, 1, 0, bias=False),\n",
    "                                    nn.BatchNorm2d(output_channels),\n",
    "                                    )\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.Conv1x1(x)\n",
    "\n",
    "        y1 = self.S1(x)\n",
    "        y2 = self.S2(x)\n",
    "        y3 = self.S3(x)\n",
    "\n",
    "        y = torch.cat((y1, y2, y3), dim=1)\n",
    "        y = self.relu(x + self.output(y))\n",
    "\n",
    "        return y\n",
    "\n",
    "\n",
    "# Dectector Head\n",
    "class DetectHead(nn.Module):\n",
    "    def __init__(self, input_channels, category_num):\n",
    "        super(DetectHead, self).__init__()\n",
    "        self.conv1x1 = Conv1x1(input_channels, input_channels)\n",
    "\n",
    "        self.obj_layers = Head(input_channels, 1)\n",
    "        self.reg_layers = Head(input_channels, 4)\n",
    "        self.cls_layers = Head(input_channels, category_num)\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1x1(x)\n",
    "\n",
    "        obj = self.sigmoid(self.obj_layers(x))\n",
    "        reg = self.reg_layers(x)\n",
    "        cls = self.softmax(self.cls_layers(x))\n",
    "\n",
    "        return torch.cat((obj, reg, cls), dim=1)\n",
    "\n",
    "\n",
    "class Detector(nn.Module):\n",
    "    def __init__(self, category_num, load_param):\n",
    "        super(Detector, self).__init__()\n",
    "\n",
    "        self.stage_repeats = [4, 8, 4]\n",
    "        self.stage_out_channels = [-1, 24, 48, 96, 192]\n",
    "        self.backbone = ShuffleNetV2(self.stage_repeats, self.stage_out_channels, load_param)\n",
    "\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "        self.avg_pool = nn.AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.SPP = SPP(sum(self.stage_out_channels[-3:]), self.stage_out_channels[-2])\n",
    "\n",
    "        self.detect_head = DetectHead(self.stage_out_channels[-2], category_num)\n",
    "\n",
    "    def forward(self, x):\n",
    "        P1, P2, P3 = self.backbone(x)\n",
    "        P3 = self.upsample(P3)\n",
    "        P1 = self.avg_pool(P1)\n",
    "        P = torch.cat((P1, P2, P3), dim=1)\n",
    "\n",
    "        y = self.SPP(P)\n",
    "\n",
    "        return self.detect_head(y)\n",
    "\n",
    "model = Detector(10,True)\n",
    "model.load_state_dict(torch.load(\"/files/weight_AP050.185523_300-epoch.pth\"))\n",
    "model.eval()\n",
    "\n",
    "def handle_preds(preds, device, conf_thresh=0.25, nms_thresh=0.45):\n",
    "    total_bboxes, output_bboxes  = [], []\n",
    "    # 将特征图转换为检测框的坐标\n",
    "    N, C, H, W = preds.shape\n",
    "    bboxes = torch.zeros((N, H, W, 6))\n",
    "    pred = preds.permute(0, 2, 3, 1)\n",
    "    # 前背景分类分支\n",
    "    pobj = pred[:, :, :, 0].unsqueeze(dim=-1)\n",
    "    # 检测框回归分支\n",
    "    preg = pred[:, :, :, 1:5]\n",
    "    # 目标类别分类分支\n",
    "    pcls = pred[:, :, :, 5:]\n",
    "\n",
    "    # 检测框置信度\n",
    "    bboxes[..., 4] = (pobj.squeeze(-1) ** 0.6) * (pcls.max(dim=-1)[0] ** 0.4)\n",
    "    bboxes[..., 5] = pcls.argmax(dim=-1)\n",
    "\n",
    "    # 检测框的坐标\n",
    "    gy, gx = torch.meshgrid([torch.arange(H), torch.arange(W)])\n",
    "    bw, bh = preg[..., 2].sigmoid(), preg[..., 3].sigmoid() \n",
    "    bcx = (preg[..., 0].tanh() + gx.to(device)) / W\n",
    "    bcy = (preg[..., 1].tanh() + gy.to(device)) / H\n",
    "\n",
    "    # cx,cy,w,h = > x1,y1,x2,y1\n",
    "    x1, y1 = bcx - 0.5 * bw, bcy - 0.5 * bh\n",
    "    x2, y2 = bcx + 0.5 * bw, bcy + 0.5 * bh\n",
    "\n",
    "    bboxes[..., 0], bboxes[..., 1] = x1, y1\n",
    "    bboxes[..., 2], bboxes[..., 3] = x2, y2\n",
    "    bboxes = bboxes.reshape(N, H*W, 6)\n",
    "    total_bboxes.append(bboxes)\n",
    "        \n",
    "    batch_bboxes = torch.cat(total_bboxes, 1)\n",
    "\n",
    "    # 对检测框进行NMS处理\n",
    "    for p in batch_bboxes:\n",
    "        output, temp = [], []\n",
    "        b, s, c = [], [], []\n",
    "        # 阈值筛选\n",
    "        t = p[:, 4] > conf_thresh\n",
    "        pb = p[t]\n",
    "        for bbox in pb:\n",
    "            obj_score = bbox[4]\n",
    "            category = bbox[5]\n",
    "            x1, y1 = bbox[0], bbox[1]\n",
    "            x2, y2 = bbox[2], bbox[3]\n",
    "            s.append([obj_score])\n",
    "            c.append([category])\n",
    "            b.append([x1, y1, x2, y2])\n",
    "            temp.append([x1, y1, x2, y2, obj_score, category])\n",
    "        # Torchvision NMS\n",
    "        if len(b) > 0:\n",
    "            b = torch.Tensor(b).to(device)\n",
    "            c = torch.Tensor(c).squeeze(1).to(device)\n",
    "            s = torch.Tensor(s).squeeze(1).to(device)\n",
    "            keep = torchvision.ops.batched_nms(b, s, c, nms_thresh)\n",
    "            for i in keep:\n",
    "                output.append(temp[i])\n",
    "        output_bboxes.append(torch.Tensor(output))\n",
    "    return output_bboxes\n",
    "\n",
    "ori_img = cv2.imread(\"/content/01460.jpg\")\n",
    "res_img = cv2.resize(ori_img, (512, 512), interpolation = cv2.INTER_LINEAR) \n",
    "img = res_img.reshape(1, 512, 512, 3)\n",
    "img = torch.from_numpy(img.transpose(0, 3, 1, 2))\n",
    "img = img.to(torch.device(\"cpu\")).float() / 255.0\n",
    "preds = model(img)\n",
    "\n",
    "output = handle_preds(preds, torch.device(\"cpu\"), 0.5, 0.2)\n",
    "\n",
    "LABEL_NAMES = [\"NM\",\n",
    "              \"M\",\n",
    "              \"TO\",\n",
    "              \"TY\",\n",
    "              \"P\",\n",
    "              \"TR\",\n",
    "              \"TG\"]\n",
    "    \n",
    "output = handle_preds(preds, torch.device(\"cpu\"), 0.5, 0.3)\n",
    "\n",
    "LABEL_NAMES = [\"M\",\n",
    "              \"NM\",\n",
    "              \"P\",\n",
    "              \"TR\",\n",
    "              \"TY\",\n",
    "              \"TG\",\n",
    "              \"TO\"]\n",
    "\n",
    "    \n",
    "H, W, _ = ori_img.shape\n",
    "scale_h, scale_w = H / 512, W / 512\n",
    "\n",
    "for box in output[0]:\n",
    "    print(box)\n",
    "    box = box.tolist()\n",
    "       \n",
    "    obj_score = box[4]\n",
    "    category = LABEL_NAMES[int(box[5])]\n",
    "\n",
    "    x1, y1 = int(box[0] * W), int(box[1] * H)\n",
    "    x2, y2 = int(box[2] * W), int(box[3] * H)\n",
    "\n",
    "    cv2.rectangle(ori_img, (x1, y1), (x2, y2), (255, 255, 0), 2)\n",
    "    cv2.putText(ori_img, '%.2f' % obj_score, (x1, y1 - 5), 0, 0.7, (0, 255, 0), 2)\t\n",
    "    cv2.putText(ori_img, category, (x1, y1 - 25), 0, 0.7, (0, 255, 0), 2)\n",
    "\n",
    "cv2.imwrite(\"result.png\", ori_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Python Callback Function and Helper Functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pushing the picture through the pipeline\n",
    "In this example, we use contiguous memory arrays for sending and receiving data via DMA.\n",
    "\n",
    "The size of the buffer depends on the size of the input or output data.  The example images are 640x360 (same size as training and test data), and we will use `pynq.allocate` to allocate contiguous memory.\n",
    "\n",
    "### Callback function\n",
    "The callback function:\n",
    "  - Will be called on each batch of images (will be called many times)\n",
    "  - Is prvided with a list of tuples of (image path, RGB image)\n",
    "  - It should return a dictionary with an entry for each image:\n",
    "    - Key: Image name (`img_path.name`)\n",
    "    - Value: Dictionary of item type and bounding box (keys: `type`, `x`, `y`, `width`, `height`)\n",
    "\n",
    "See the code below for an example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_callback(rgb_imgs):\n",
    "    object_locations_by_image = {}\n",
    "    \n",
    "    \n",
    "    for (img_path, img) in rgb_imgs:\n",
    "        object_locations = []\n",
    "        \n",
    "        # Resize the image (this is part of your runtime)\n",
    "        img_resized = cv2.resize(img, (512,512), interpolation = cv2.INTER_AREA)\n",
    "        \n",
    "        # implement your own inference code here\n",
    "     \n",
    "     \n",
    "     \n",
    "        # need to unpack data here, then iterate to append object locations into list\n",
    "        #\n",
    "\n",
    "        # Appending fake image location, since this example doesn't actually perform object detection \n",
    "        object_locations.append({\"type\":1, \"x\":1168, \"y\":639, \"width\":457, \"height\":245})\n",
    "        object_locations.append({\"type\":1, \"x\":831, \"y\":626, \"width\":77, \"height\":57})\n",
    "        object_locations.append({\"type\":2, \"x\":753, \"y\":628, \"width\":44, \"height\":52})\n",
    "        \n",
    "        # Save to dictionary by image filename\n",
    "        object_locations_by_image[img_path.name] = object_locations\n",
    "        \n",
    "    return object_locations_by_image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Running Object Detection\n",
    "\n",
    "Call the following function to run the object detection.  Extra debug output is enabled when `debug` is `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team.run(my_callback, debug=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
